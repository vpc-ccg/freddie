import os
configfile: 'config.yaml'

configfile: 'config.yaml'
localrules:
    all,
    cat_edges_tsv,

for k in config.keys():
    if not k.startswith('override_'):
        continue
    keys = k[len('override_'):].split('_')
    top_dict = eval('config{}'.format(''.join(['["{}"]'.format(x) for x in keys[:-1]])))
    assert keys[-1] in top_dict
    top_dict[keys[-1]]=config[k]

def make_slurm():
    os.makedirs('slurm'.format(outpath), mode=0o777, exist_ok=True)

def get_which(command):
    result = subprocess.run(['which', command], stdout=subprocess.PIPE)
    return result.stdout.decode('ascii').rstrip()

outpath      = config['outpath'].rstrip('/')
preprocess_d = '{}/preprocess'.format(outpath)
workspace_d  = '{}/workspace'.format(outpath)
output_d     = '{}/output'.format(outpath)
graphs_d     = '{}/graphs'.format(outpath)
plots_d      = '{}/plots'.format(outpath)
short_d      = '{}/short'.format(outpath)


simu_tools = ['truth', 'isoform']
venn_tools = list()
overlaps = dict()
simu_samples = set()

for tool in config['tools']:
    if tool == 'flair':
        for r in config['gtf_sample_rates']:
            t = 'flair.{:.2f}'.format(r)
            simu_tools.append(t)
            if r in [1.00]:
                venn_tools.append((t, 'FLAIR ({:.0%})'.format(r)))
    else:
        simu_tools.append(tool)
        if tool == 'freddie':
            venn_tools.append((tool, 'Freddie'))  
        elif tool == 'stringtie':
            venn_tools.append((tool, 'StringTie2'))  

for s in config['samples']:
    overlaps[s]=dict()
    for m in config['mappers']:
        overlaps[s][m]=dict()
        if config['samples'][s]['reads_info'] == 0:
            continue
        simu_samples.add(s)
        for t in simu_tools:
            overlaps[s][m][t] = dict()
            for l in open('{}/{}/{}/{}.overlaps.tsv'.format(graphs_d, s, m, t)):
                c,i1,i2 = l.rstrip().split('\t')
                if i1==i2:
                    continue
                if not c in overlaps[s][m][t]:
                    overlaps[s][m][t][c]=dict()
                if i1.startswith(t) and i2.startswith(t):
                    i1,i2 = sorted((i1,i2))
                overlaps[s][m][t][c][i1] = overlaps[s][m][t][c].get(i1, set()) | {i2}

rule all:
    input:
        [
            '{p}/{s}/{m}/{t}.alignments/{c}.{f}'.format(
                p=graphs_d,
                s=s,
                m=m,
                t=t,
                c=c,
                f=f,
            )
            for f in ['edges.tsv', 'jobs']
                for s in overlaps 
                    for m in overlaps[s] 
                        for t in overlaps[s][m]
                            for c in overlaps[s][m][t]
        ],
        [
            '{p}/{s}/{m}/{t}.edges.tsv'.format(
                p=graphs_d,
                s=s,
                m=m,
                t=t,
            )
            for s in overlaps 
                for m in overlaps[s] 
                    for t in overlaps[s][m]
        ],
        [
            '{p}/{s}/{m}/accuracy'.format(
                p=plots_d,
                s=s,
                m=m,
            )
            for s in simu_samples 
                for m in overlaps[s] 
        ],
        [
            '{p}/{s}/{m}/venn.{f}.pdf'.format(
                p=plots_d,
                s=s,
                m=m,
                f=f,
            )
            for s in overlaps 
                for m in overlaps[s]
                    for f in ['exons', 'introns']
        ],
        [
            '{p}/{s}/{m}/{t}_SJ.out.tab'.format(
                p=short_d,
                s=s,
                m=m,
                t=t,
            )
            for s in overlaps 
                for m in overlaps[s]
                    for t,_ in venn_tools
        ],

rule align_to_transcript_jobs:
    input:
        direct = '{}/{{sample}}/{{mapper}}/{{tool}}.transcripts/{{contig}}'.format(graphs_d),
    output:
        jobs   = '{}/{{sample}}/{{mapper}}/{{tool}}.alignments/{{contig}}.jobs'.format(graphs_d),
    run:
        s = wildcards.sample
        m = wildcards.mapper
        t = wildcards.tool
        c = wildcards.contig
        target_tmpl = '{p}/{s}/{m}/{t}.transcripts/{c}/{{i1}}.fa'.format(
            p=graphs_d,
            s=s,
            m=m,
            t=t,
            c=c,
        )
        query_tmpl  = '{p}/{s}/{m}/{{qt}}.transcripts/{c}/{{i2}}.fa'.format(
            p=graphs_d,
            s=s,
            m=m,
            t=t,
            c=c,
        )
        jobs = open(output.jobs, 'w+')
        for i1,i2s in overlaps[s][m][t][c].items():
            target = target_tmpl.format(i1=i1)
            for i2 in i2s:
                query = query_tmpl.format(qt=i2.split('_')[0], i2=i2)
                jobs.write(
                    'minimap2 -t 1 --splice {} {} 2> /dev/null | grep "tp:A:P" | sort -k10,10nr | awk \'BEGIN{{OFS=\"\\t\"}} NR==1 {{print $1,$6,$10/(($2+$7)/2)}}\'\n'.format(
                        target,
                        query,
                    )
                )
rule edges_tsv:
    input:
        jobs = '{}/{{sample}}/{{mapper}}/{{tool}}.alignments/{{contig}}.jobs'.format(graphs_d),
    output:
        cons = '{}/{{sample}}/{{mapper}}/{{tool}}.alignments/{{contig}}.edges.tsv'.format(graphs_d),
    resources:
        mem_mb = 32*1024,
        time   = 60*24-1,
    conda:
        'envs/accuracy.yml'
    threads:
        32
    shell:
        'parallel --jobs {threads} < {input.jobs} > {output.cons}'


rule cat_edges_tsv:
    input:
        lambda wildcards: ['{}/{{sample}}/{{mapper}}/{{tool}}.alignments/{}.edges.tsv'.format(graphs_d, c)
            for c in overlaps[wildcards.sample][wildcards.mapper][wildcards.tool]
        ],
    output:
        '{}/{{sample}}/{{mapper}}/{{tool}}.edges.tsv'.format(graphs_d),
    shell:
        'cat {input} > {output}'

rule accuracy_plots:
    input:
        script = 'py/freddie_accuracy.py',
        graphs = lambda wildcards: [
            '{}/{}/{}/{}.edges.tsv'.format(graphs_d, wildcards.sample, wildcards.mapper, t)
            for t in overlaps[wildcards.sample][wildcards.mapper]
        ],
    conda:
        'envs/accuracy.yml'
    output:
        direct = directory('{}/{{sample}}/{{mapper}}/accuracy'.format(plots_d)),
    params:
        in_direct = '{}/{{sample}}/{{mapper}}'.format(graphs_d),
    shell:
        '{input.script} -id {params.in_direct} -od {output.direct}'


rule sim_gtf:
    input:
        bed = '{}/{{sample}}/{{mapper}}/truth.bed'.format(graphs_d),
        gtf = lambda wildcards: config['references'][config['samples'][wildcards.sample]['ref']]['annot'],
    output:
        gtf = '{}/{{sample}}/{{mapper}}/truth.gtf'.format(graphs_d),
    run:
        tids = set()
        for l in open(input.bed):
            l = l.rstrip().split('\t')
            tid = l[3].split('_')[-1]
            tids.add(tid)
        print(f'There are {len(tids)} transcripts')
        outfile = open(output.gtf, 'w+')
        for line in open(input.gtf):
            if line[0]=='#':
                continue
            l = line.rstrip().split('\t')
            info = l[8]
            info = [x.strip().split(' ') for x in info.strip(';').split(';')]
            info = {x[0]:x[1].strip('"') for x in info}
            if not 'transcript_id' in info:
                continue
            if not info['transcript_id'] in tids:
                continue
            outfile.write(line)
        outfile.close()

def get_t_annot(sample, mapper):
    if config['samples'][sample]['reads_info'] == 0:
        ref = config['samples'][sample]['ref']
        return config['references'][ref]['annot']
    else:
        return '{}/{}/{}/truth.gtf'.format(graphs_d,sample,mapper)


rule venn_plots:
    input:
        script = 'py/freddie_venn.py',
        tool_gtfs = lambda wildcards: [
            f'{output_d}/{wildcards.sample}/{wildcards.mapper}/{t}.isoforms.gtf'
            for t,_ in venn_tools
        ],
        t_gtf = lambda wildcards: get_t_annot(wildcards.sample, wildcards.mapper),
    output:
        exons_pdf = '{}/{{sample}}/{{mapper}}/venn.exons.pdf'.format(plots_d),
        introns_pdf = '{}/{{sample}}/{{mapper}}/venn.introns.pdf'.format(plots_d),
        exons_tsv = '{}/{{sample}}/{{mapper}}/venn.exons.tsv'.format(plots_d),
        introns_tsv = '{}/{{sample}}/{{mapper}}/venn.introns.tsv'.format(plots_d),
    params:
        tool_names = ['"{}"'.format(n) for _,n in venn_tools],
        t_name = lambda wildcards: 'Annotations' if config['samples'][wildcards.sample]['reads_info'] == 0 else 'Truth',
        hides = lambda wildcards: '-x Annotations' if config['samples'][wildcards.sample]['reads_info'] == 0 else '',
        prefix = '{}/{{sample}}/{{mapper}}/venn'.format(plots_d),
    conda:
        'envs/accuracy.yml'
    params:
        in_direct = '{}/{{sample}}/{{mapper}}'.format(graphs_d),
    shell:
        '{input.script} -o {params.prefix} -a {input.tool_gtfs} {input.t_gtf} -n {params.tool_names} {params.t_name} -T {params.t_name} {params.hides}'

rule star_index:
    input:
        gtf = '{}/{{sample}}/{{mapper}}/{{tool}}.isoforms.gtf'.format(output_d),
        genome = lambda wildcards: config['references'][config['samples'][wildcards.sample]['ref']]['genome'],
    output:
        index = directory('{}/{{sample}}/{{mapper}}/{{tool}}_star_index'.format(short_d)),
    params:
        tmp_dir = '{}/{{sample}}/{{mapper}}/{{tool}}_star_tmp'.format(short_d),
    threads:
        32
    conda:
        'envs/star.yml'
    shell:
        'rm -rf {params.tmp_dir} && '
        'mkdir {output.index} && '
        'STAR'
        ' --runMode genomeGenerate'
        ' --genomeFastaFiles {input.genome}'
        ' --sjdbGTFfile {input.gtf}'
        ' --genomeDir {output.index}'
        ' --outTmpDir {params.tmp_dir}'
        ' --runThreadN {threads}'

rule star_map:
    input:
        reads  = lambda wildcards: config['samples'][wildcards.sample]['short-reads'],
        index = '{}/{{sample}}/{{mapper}}/{{tool}}_star_index'.format(short_d),
    output:
        sam = '{}/{{sample}}/{{mapper}}/{{tool}}_SJ.out.tab'.format(short_d),
    params:
        prefix = '{}/{{sample}}/{{mapper}}/{{tool}}_'.format(short_d),
    threads:
        64
    conda:
        'envs/star.yml'
    shell:
        'STAR'
        ' --runMode alignReads'
        ' --genomeDir {input.index}'
        ' --readFilesIn {input.reads}'
        ' --outSAMtype SAM'
        ' --outFileNamePrefix {params.prefix}'
        ' --readFilesCommand zcat'
        ' --runThreadN {threads}'